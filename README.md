# ğŸ¤– Multi-PDF Chat App (Local AI Assistant)

A lightweight, privacy-first local chat app that lets you upload multiple PDFs and chat with them â€” powered by local AI models for summarization and question answering. Works fully offline and designed for low-end machines (8GB RAM friendly).

---

## ğŸš€ Features

- ğŸ“š **Multi-PDF Upload**: Upload and query multiple PDFs at once.
- ğŸ§  **Local LLM Support**: Uses lightweight models for summarization and QA.
- ğŸ’¬ **Chat Interface**: Clean conversational UI built with Streamlit.
- ğŸ” **Search Chat History** *(optional)*.
- ğŸŒ **Translate Chat to Other Languages** *(optional)*.
- ğŸ“Š **Chat Stats**: Total messages, word count, etc.
- ğŸ” **Undo Last Message**.
- ğŸ’¾ **Save & Load Sessions** (JSON-based).
- ğŸ§  **Recall User Inputs**: Assistant can show all your past questions.

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: Streamlit
- **Backend**: Python (Langchain / local LLM)
- **File Handling**: PyMuPDF / PDFMiner
- **Lightweight RAG Setup**: FAISS or in-memory index

---

## ğŸ“¦ Installation

1. **Clone the repo**

```bash
git clone https://github.com/your-username/multi-pdf-chat-app
cd multi-pdf-chat-app

2. **Create Virtual Environment**
python -m venv venv
venv\Scripts\activate  # On Windows

3. **Install Dependencies**
pip install -r requirements.txt

4. **Run the App**
streamlit run chatapp.py

